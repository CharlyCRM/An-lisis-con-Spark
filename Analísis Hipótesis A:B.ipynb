{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://f4c15a36f446:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>An치lisis Exploratorio</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff5a0fc090>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuraci칩n de SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, StringType, IntegerType, DateType\n",
    "from pyspark.sql.functions import mean, round, std, max, min\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"An치lisis Exploratorio\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ticker: string (nullable = true)\n",
      " |-- open: string (nullable = true)\n",
      " |-- high: string (nullable = true)\n",
      " |-- low: string (nullable = true)\n",
      " |-- close: string (nullable = true)\n",
      " |-- volume: string (nullable = true)\n",
      " |-- dividends: string (nullable = true)\n",
      " |-- stock splits: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- ccy: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importo el fichero localizado en la misma ruta del projecto\n",
    "data = spark.read.options(inferShema='True', delimiter= ',', header=True).csv('work/CSV_stocks_2021.csv')\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al importar el fichero e indicarle en la configuraci칩n que realizara la inferencia de datos de forma autom치tica **inferSchema=True**, observo como las columnas han sido inferidas a datos de tipo String, cuando realmente nos encontramos con diversos tipos de datos. Por este motivo, volver칠 a cargar los datos infiriendo manualmente en el tipo de dato para cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ticker: string (nullable = true)\n",
      " |-- open: float (nullable = true)\n",
      " |-- high: float (nullable = true)\n",
      " |-- low: float (nullable = true)\n",
      " |-- close: float (nullable = true)\n",
      " |-- volume: integer (nullable = true)\n",
      " |-- dividends: float (nullable = true)\n",
      " |-- stock splits: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- ccy: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defino el Schema manualmente\n",
    "custom_schema = StructType([\n",
    "    StructField(\"ticker\", StringType(), True),\n",
    "    StructField(\"open\", FloatType(), True),\n",
    "    StructField(\"high\", FloatType(), True),\n",
    "    StructField(\"low\", FloatType(), True),\n",
    "    StructField(\"close\", FloatType(), True),\n",
    "    StructField(\"volume\", IntegerType(), True),\n",
    "    StructField(\"dividends\", FloatType(), True),\n",
    "    StructField(\"stock splits\", IntegerType(), True),\n",
    "    StructField(\"date\", DateType(), True),\n",
    "    StructField(\"ccy\", StringType(), True)])\n",
    "\n",
    "data = spark.read.schema(custom_schema).option(\"delimiter\", \",\").option(\"header\", \"true\").csv('work/CSV_stocks_2021.csv')\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 游꿉 Contraste de Hip칩tesis A/B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio vamos se va a analizar la cotizaci칩n de apertura para el valor burs치til **HON**. *(Empresa multinacional estadounidense que opera en varias 치reas como la industria aeroespacial, la fabricaci칩n de productos para el control de seguridad y automatizaci칩n)*. \n",
    "\n",
    "Para ello vamos a dividir los 252 periodos en dos partes y compararlos entre s칤:\n",
    "- Un **Periodo Inicial** que inicia el 4 de enero del 2021 y finaliza el 30 de junio del 2021.\n",
    "- Un **Periodo Final** que inicia el 01 de julio del 2021 y finaliza el 30 de diciembre del 2021 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------+---------+---------+-------+---------+------------+----------+---+\n",
      "|ticker|     open|     high|      low|    close| volume|dividends|stock splits|      date|ccy|\n",
      "+------+---------+---------+---------+---------+-------+---------+------------+----------+---+\n",
      "|   HON|207.45502|209.42142|206.14735|209.12645|1406400|      0.0|           0|2020-12-31|USD|\n",
      "|   HON| 209.2641|209.43124|202.89297|204.45625|2328900|      0.0|           0|2021-01-04|USD|\n",
      "|   HON|203.50256|206.65863|203.50256| 204.9577|2172100|      0.0|           0|2021-01-05|USD|\n",
      "|   HON|205.93106|210.38495|205.71475|208.69385|2747900|      0.0|           0|2021-01-06|USD|\n",
      "|   HON|209.31328|210.41446|207.25839|209.03798|2057300|      0.0|           0|2021-01-07|USD|\n",
      "|   HON|209.22478|209.82452|204.18097|206.50131|3278900|      0.0|           0|2021-01-08|USD|\n",
      "|   HON|204.61356|206.09819|204.33827|204.85936|2938900|      0.0|           0|2021-01-11|USD|\n",
      "|   HON|204.36778|205.96056|201.81146|205.37065|2498800|      0.0|           0|2021-01-12|USD|\n",
      "|   HON|204.78072|205.11499| 202.9323|203.54189|2145100|      0.0|           0|2021-01-13|USD|\n",
      "|   HON|204.54475|206.25552| 203.6992|205.10518|3661500|      0.0|           0|2021-01-14|USD|\n",
      "|   HON| 204.0433|204.36777|201.75246|202.50952|3887500|      0.0|           0|2021-01-15|USD|\n",
      "|   HON| 204.7414|205.25266|202.98146|203.28625|2656300|      0.0|           0|2021-01-19|USD|\n",
      "|   HON|204.42676|205.16415|203.19777|204.58408|2452400|      0.0|           0|2021-01-20|USD|\n",
      "|   HON|203.38457| 204.3186|201.65414|201.78195|2705100|      0.0|           0|2021-01-21|USD|\n",
      "|   HON|200.82826|201.02492|198.00648|198.85204|3502700|      0.0|           0|2021-01-22|USD|\n",
      "|   HON|197.95732|199.15681|196.73816|198.47841|4737700|      0.0|           0|2021-01-25|USD|\n",
      "|   HON| 200.4153|201.32968|197.60335|  197.682|2201900|      0.0|           0|2021-01-26|USD|\n",
      "|   HON|194.78159|197.38707|193.22813|196.03026|4108600|      0.0|           0|2021-01-27|USD|\n",
      "|   HON| 197.2494|201.89995|196.27605|199.43211|3731700|      0.0|           0|2021-01-28|USD|\n",
      "|   HON|193.20847|197.56404| 191.2814|192.08762|4635100|      0.0|           0|2021-01-29|USD|\n",
      "+------+---------+---------+---------+---------+-------+---------+------------+----------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "N칰mero filas: 252\n"
     ]
    }
   ],
   "source": [
    "# Filtro los datos por el valor HON\n",
    "data_hon = data.filter(data.ticker == 'HON').orderBy('date')\n",
    "data_hon.show()\n",
    "print(\"N칰mero filas:\",data_hon.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, el dataframe inicia en la **fecha 31-12-2020**. Como este valor est치 fuera de nuestro an치lisis *(Se centra en los resultados del 2021)* vamos a proceder a eliminarlo m치s adelante. Cuando transformemos el datafrade de **Spark a Pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-04\n"
     ]
    }
   ],
   "source": [
    "# Transformo los datos en dataframe de pandas\n",
    "pandas_data_hon = data_hon.toPandas()\n",
    "\n",
    "# Elimino la primera fila ya que corresponde al a침o 2020\n",
    "pandas_data_hon = pandas_data_hon.drop(pandas_data_hon.index[0])\n",
    "print(pandas_data_hon['date'][1])\n",
    "\n",
    "# Usando Numpy extraigo la columna open y la conversitmos en un array unidemensional \n",
    "hon_array = np.array(pandas_data_hon['open']).ravel()\n",
    "#print(hon_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media del Periodo Inicial:  213.36190856449187\n",
      "Media del Periodo Final:  219.47718298339845\n",
      "--------------------------------------------------\n",
      "P-Value: 7.464256120088e-07\n"
     ]
    }
   ],
   "source": [
    "# Divido el array en 2 para comparar dos periodos y determinar si se ha producido un cambio significativo\n",
    "hon_array_split = np.array_split(hon_array, 2)\n",
    "\n",
    "hon_array_0 = hon_array_split[0].astype(float)\n",
    "hon_mean_0 = np.mean(hon_array_0)\n",
    "\n",
    "hon_array_1 = hon_array_split[1].astype(float)\n",
    "hon_mean_1 = np.mean(hon_array_1)\n",
    "\n",
    "print(\"Media del Periodo Inicial: \", hon_mean_0)\n",
    "print(\"Media del Periodo Final: \", hon_mean_1)\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Aplicamos la t de student a las 2 muestras\n",
    "hon_ttest_result = stats.ttest_ind(hon_array_0, hon_array_1, equal_var=False)\n",
    "p_value = hon_ttest_result.pvalue\n",
    "print(\"P-Value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 游늳 Resultado del An치lisis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El an치lisis de dos periodos de cotizaci칩n de las acciones de **Honeywell Internacional Inc.** revela un cambio de **($6.12)**, entre la media del periodo inicial **($213.36)** y la media del periodo final **($219.48)**. Este aumento en la media sugiere un **incremento en el valor promedio de las acciones de Honeywell durante el segundo periodo**. Sin embargo, para determinar la significancia estad칤stica de este cambio, es esencial considerar el P-Value obtenido a trav칠s de la prueba t de Student.\n",
    " \n",
    "La prueba t de Student confirma la significancia estad칤stica de esta diferencia, evidenciada por un P-Value bajo **(7.46)**. Esta informaci칩n sugiere un rendimiento positivo en el valor de las acciones durante el segundo periodo, proporcionando a inversores y analistas una base s칩lida para considerar ajustes en sus estrategias de inversi칩n."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
